# -*- coding: utf-8 -*-
"""data crawling(BeautifulSoup all code) .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12wwfamROLupU9j3cfC1Ylzw6_XVmpf8w
"""



import urllib.request
from bs4 import BeautifulSoup

#scraping web link
address= 'https://www.rottentomatoes.com/m/incredibles_2/reviews/'

page = urllib.request.urlopen(address)
soup = BeautifulSoup(page,'html.parser')
#print full html page of address
print (soup.prettify())

"""# some simple ways to navigate that data structure"""

soup.title

soup.title.name

soup.title.string

soup.title.parent.name

soup.p

soup.p['class']

soup.a

soup.find_all('a')

soup.find_all('p')



"""# common task is extracting all"""

#all the URLs found within a pageâ€™s <a> tags:

for link in soup.find_all('a'):
    print(link.get('href'))

#extracting all the text from a page:
print(soup.get_text())













